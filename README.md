# ds-takehome
Repository for Data Scientist take home test provided by Talentport

# Data Scientist Take-Home Project

This project consists of three subtests:
1. SQL-based e-commerce transaction analysis
2. Python-based credit risk modeling (under development)
3. R-based model validation (not yet configured)

## ðŸ”§ Environment Setup (Python Only)

Ensure you have Python 3.11+ installed.

### 1. Clone the repository
```bash
git clone https://github.com/your-username/ds-takehome.git
cd ds-takehome
```

### 2. Create and activate virtual environment
```bash
python -m venv .venv
# Activate:
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 3. Install required Python packages
```bash
pip install -r requirements.txt
```

**If you haven't created it yet**, freeze your installed packages into `requirements.txt`:
```bash
pip freeze > requirements.txt
```

### 4. Start the Jupyter Notebook
```bash
jupyter notebook
```

Open `notebooks/your_notebook_file.ipynb` to view and run the Python analysis.

## ðŸ“‚ Project Structure

```
ds-takehome/
â”‚
â”œâ”€â”€ data/                        # Contains the raw CSV files
â”‚   â”œâ”€â”€ e_commerce_transactions.csv
â”‚   â””â”€â”€ credit_scoring.csv
â”‚
â”œâ”€â”€ notebooks/                  # Python notebooks for modeling
â”‚   â””â”€â”€ B_modeling.ipynb
â”‚   â””â”€â”€ sql_analysis.ipynb
â”‚
â”œâ”€â”€ analysis.sql                # SQL script for subtest 1
â”œâ”€â”€ README.md                   # You're here
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€.gitignore 
```

## ðŸ“Œ Notes

- SQL analysis is written in `analysis.sql` and can be executed using DuckDB or any SQL engine that supports reading CSV files.
- Python code uses DuckDB to query directly from the CSV files, and Scikit-learn for modeling.
- R environment setup and validation steps will be added later.
